{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the following libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "import tifffile as tiff\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### directory & filepaths\n",
    "data_dir = '/home/shamini/data1/data_orig/data/spatial/xenium/10xGenomics/cell_seg_brain_cancer/'\n",
    "out = '/home/shamini/data/projects/spatial_workshop/out/module6/'\n",
    "os.makedirs(out+'script05_figures/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = 'transcripts.parquet'\n",
    "image = 'morphology_focus_0000.ome.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript = pd.read_parquet(data_dir+'out/'+transcripts)\n",
    "iF = tiff.imread(data_dir+'out/morphology_focus/'+image)\n",
    "#he = tiff.imread(data_dir+he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.2125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript[['x_location']] = df_transcript[['x_location']]/scale\n",
    "df_transcript[['y_location']] = df_transcript[['y_location']]/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin_cut = int(10000/scale)\n",
    "xmax_cut = int(11000/scale)\n",
    "\n",
    "ymin_cut = int(6000/scale)\n",
    "ymax_cut = int(7000/scale)\n",
    "\n",
    "print(xmin_cut, xmax_cut, ymin_cut, ymax_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_subset = df_transcript[((df_transcript['x_location'] > xmin_cut) & (df_transcript['x_location'] < xmax_cut)) & ((df_transcript['y_location'] > ymin_cut) & (df_transcript['y_location'] < ymax_cut))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=transcripts_subset, x='x_location', y='y_location', s=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = int(transcripts_subset['x_location'].min())\n",
    "max_x = int(transcripts_subset['x_location'].max())\n",
    "\n",
    "min_y = int(transcripts_subset['y_location'].min())\n",
    "max_y = int(transcripts_subset['y_location'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reset the coordinates to 0\n",
    "transcripts_subset['x_location'] = transcripts_subset['x_location'] - min_x\n",
    "transcripts_subset['y_location'] = transcripts_subset['y_location'] - min_y\n",
    "\n",
    "transcripts_subset.to_csv(out+'transcripts_subset_all_genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crop the image\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "iF_crop = iF[:, min_y:max_y, min_x:max_x]\n",
    "ax = ax.flatten()\n",
    "\n",
    "for channel in range(4):\n",
    "    ax[channel].imshow(iF_crop[channel], cmap='gray')\n",
    "    ax[channel].axis('off')\n",
    "    ax[channel].set_title(f'Channel {channel}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the cropped image\n",
    "tiff.imsave(out+'script06_objects/cropped_image.tif', iF_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "transcripts_subset_sample = transcripts_subset.sample(frac=0.3, random_state=1)\n",
    "\n",
    "axes[0].imshow(iF_crop[1,:,:], cmap='magma')\n",
    "ax = sns.scatterplot(data=transcripts_subset_sample, x='x_location', y='y_location', s=0.3, ax=axes[0], alpha=0.5, color='white')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(iF_crop[1,:,:], cmap='magma')\n",
    "ax = sns.scatterplot(data=transcripts_subset_sample, x='x_location', y='y_location', s=0.9, ax=axes[1], alpha=0.75, color='white')\n",
    "ax.set_xlim(3000, 3500)\n",
    "ax.set_ylim(3000, 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import cell boundaries and nuclear boundaries files\n",
    "cell_boundaries = pd.read_parquet(data_dir+'out/cell_boundaries.parquet')\n",
    "nuclear_boundaries = pd.read_parquet(data_dir+'out/nucleus_boundaries.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_boundaries = cell_boundaries[cell_boundaries['cell_id'].isin(df_transcript['cell_id'])]\n",
    "cell_boundaries['vertex_x'] = (cell_boundaries['vertex_x']/0.2125)\n",
    "cell_boundaries['vertex_y'] = (cell_boundaries['vertex_y']/0.2125)\n",
    "\n",
    "nuclear_boundaries = nuclear_boundaries[nuclear_boundaries['cell_id'].isin(df_transcript['cell_id'])]\n",
    "nuclear_boundaries['vertex_x'] = (nuclear_boundaries['vertex_x']/0.2125)\n",
    "nuclear_boundaries['vertex_y'] = (nuclear_boundaries['vertex_y']/0.2125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shift the coordinates to match the cropped image\n",
    "cell_boundaries['vertex_x'] = cell_boundaries['vertex_x'] - min_x\n",
    "cell_boundaries['vertex_y'] = cell_boundaries['vertex_y'] - min_y\n",
    "\n",
    "nuclear_boundaries['vertex_x'] = nuclear_boundaries['vertex_x'] - min_x\n",
    "nuclear_boundaries['vertex_y'] = nuclear_boundaries['vertex_y'] - min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_boundaries.to_parquet(out+'cell_boundaries_subset.parquet')\n",
    "nuclear_boundaries.to_parquet(out+'nuclear_boundaries_subset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check the data's shape and maximum value\n",
    "print(\"Shape of iF_crop:\", iF_crop.shape)\n",
    "for i in range(4):\n",
    "    print(f\"Channel {i} max: {np.max(iF_crop[i])}, min: {np.min(iF_crop[i])}\")\n",
    "\n",
    "# Define colors, with DAPI visualized in blue\n",
    "colors = [\n",
    "    np.array([0, 0, 1]),  # Blue for DAPI\n",
    "    np.array([1, 0, 0]),  # Red\n",
    "    np.array([0, 1, 0]),  # Green\n",
    "    np.array([1, 1, 0])   # Yellow for the fourth channel\n",
    "]\n",
    "\n",
    "# Create a composite image with 3 channels (RGB)\n",
    "composite_image = np.zeros((iF_crop.shape[1], iF_crop.shape[2], 3), dtype=np.float32)\n",
    "\n",
    "# Assign each channel to a color in RGB, using a more conservative normalization approach\n",
    "for i in range(4):\n",
    "    channel_data = iF_crop[i, :, :]\n",
    "    if np.max(channel_data) > 0:  # Avoid division by zero and unnecessary normalization\n",
    "        normalized_data = channel_data / np.max(channel_data)\n",
    "        composite_image += normalized_data[:, :, np.newaxis] * colors[i]\n",
    "\n",
    "#composite_image += channel_data[:, :, np.newaxis] * colors[i]\n",
    "\n",
    "\n",
    "# Ensure the image is normalized to the maximum of the composite_image\n",
    "#if np.max(composite_image) > 0:\n",
    "#    composite_image /= np.max(composite_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.imshow(composite_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the composite image as tiff\n",
    "tiff.imsave(out+'script05_figures/composite_image.tif', composite_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### subset adata to the cropped image\n",
    "\n",
    "adata = sc.read_h5ad(out+'adata.h5ad')\n",
    "print(f'Adata before cropping:\\n {adata}\\n')\n",
    "adata_crop = adata[adata.obs.index.isin(transcripts_subset['cell_id']),:]\n",
    "print(f'Adata after cropping:\\n {adata_crop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['PTPRC', 'ANXA1', 'STMN1']\n",
    "\n",
    "adata_crop = adata_crop[:,genes]\n",
    "adata_crop.write_h5ad(out+'adata_crop.h5ad')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_subset = transcripts_subset[transcripts_subset['feature_name'].isin(genes)]\n",
    "transcripts_subset.to_csv(out+'transcripts_subset_genes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_boundaries = cell_boundaries[cell_boundaries['cell_id'].isin(transcripts_subset['cell_id'])]\n",
    "nuclear_boundaries = nuclear_boundaries[nuclear_boundaries['cell_id'].isin(transcripts_subset['cell_id'])]\n",
    "\n",
    "cell_boundaries.to_csv(out+'cell_boundaries_subset.csv', index=False)\n",
    "nuclear_boundaries.to_csv(out+'nuclear_boundaries_subset.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
