{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **ISO2024 INTRODUCTORY SPATIAL 'OMICS ANALYSIS**\n",
    ">\n",
    ">\n",
    ">- HYBRID : TORONTO & ZOOM\n",
    ">- 9TH JULY 2024 <br>\n",
    "\n",
    ">**Module 3 : Building your spatial model ** <BR>\n",
    ">\n",
    ">**Instructor : Shamini Ayyadhury**\n",
    ">\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TOPICS COVERED\n",
    "\n",
    "* A. Normalizing your data *\n",
    "* B. Spatial and non-spatial clustering *\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "B. SPATIAL & NON-SPATIAL CLUSTERING\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the following libraries. Some of these were used in the previous notebook and we are using them here as well\n",
    "import sys # system specific parameters and functions\n",
    "import pandas as pd # data manipulation and analysis\n",
    "import numpy as np # numerical computing library\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import seaborn as sns # data visualization library based on matplotlib\n",
    "import scanpy as sc # single-cell analysis in Python\n",
    "import os # operating system dependent functionality\n",
    "\n",
    "sys.path.append('/home/shamini/data/projects/spatial_workshop/')\n",
    "sys.path.append('/home/shamini/data/projects/spatial_workshop/Banksy_py')\n",
    "import pre_processing_fnc as ppf # from here onwards we will only use the function for memory regulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### directory & filepaths\n",
    "\n",
    "data_dir = '/home/shamini/data1/data_orig/data/spatial/xenium/10xGenomics/'\n",
    "out = '/home/shamini/data/projects/spatial_workshop/out/'\n",
    "os.makedirs(out+'figures/', exist_ok=True) # create a new directory to store the output files\n",
    "os.makedirs(out+'objects/', exist_ok=True) # create a new directory to store the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT DATA\n",
    "\n",
    "'''\n",
    "ANNDATA OBJECT FROM MODULE 2\n",
    "'''\n",
    "\n",
    "adata = sc.read_h5ad(out+'module2/objects/adata.h5ad')\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the basic code for spatial and non-spatial clustering. After understanding the principles, you will be provided with an exercise using one of the various spatial clustering packages (Banksy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Take note of these packages.\n",
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import umap\n",
    "\n",
    "    \n",
    "### Perform clustering using PCA\n",
    "adata.X = adata.raw.X.copy()  # Ensure raw data is dense if needed\n",
    "sc.experimental.pp.normalize_pearson_residuals(adata)\n",
    "print('normalized')\n",
    "\n",
    "### Perform PCA\n",
    "pca = PCA(n_components=21)\n",
    "adata.obsm['sk_pca'] = pca.fit_transform(adata.X)\n",
    "print('pca done')\n",
    "\n",
    "### Compute PCA-based neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=27, algorithm='ball_tree').fit(adata.obsm['sk_pca'])\n",
    "distances, indices = nbrs.kneighbors(adata.obsm['sk_pca'])\n",
    "print('neighbors computed')\n",
    "    \n",
    "### Convert the neighbor information into a graph format suitable for Leiden clustering\n",
    "edges = [(i, indices[i, j]) for i in range(indices.shape[0]) for j in range(1, indices.shape[1])]\n",
    "print('edges created')\n",
    "\n",
    "### Create an igraph from edges\n",
    "g = ig.Graph(edges=edges)\n",
    "print('graph created')\n",
    "\n",
    "### Perform Leiden clustering on the constructed graph\n",
    "partition = la.find_partition(g, la.RBConfigurationVertexPartition, resolution_parameter=0.3)\n",
    "print('clustering done')\n",
    "    \n",
    "adata.obs['leiden_pca'] = partition.membership\n",
    "    \n",
    "       \n",
    "### Initialize UMAP reducer\n",
    "reducer = umap.UMAP(n_neighbors=27, min_dist=0.3, metric='euclidean')\n",
    "\n",
    "### Fit and transform the data using the precomputed graph\n",
    "adata.obsm['umap_graph_pca'] = reducer.fit_transform(adata.obsm['sk_pca'])\n",
    "print('umap done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot embedding\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.scatterplot(x=adata.obsm['umap_graph_pca'][:,0], y=adata.obsm['umap_graph_pca'][:,1], hue=adata.obs['leiden_pca'], palette='tab20', s=3, ax=axes[0])\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "sns.scatterplot(x=adata.obs['x_location'], y=adata.obs['y_location'], hue=adata.obs['leiden_pca'], s=1, palette='tab20b', ax=axes[1])\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Perform clustering using spatial coordinates\n",
    "spatial = adata.obs[['x_location', 'y_location']].values\n",
    "print('spatial coordinates extracted')    \n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=27, algorithm='ball_tree').fit(spatial)\n",
    "distances, indices = nbrs.kneighbors(spatial)\n",
    "print('neighbors computed directly from spatial coordinates')\n",
    "\n",
    "### Create edges based on k-nearest neighbors\n",
    "edges = [(i, indices[i, j]) for i in range(indices.shape[0]) for j in range(1, indices.shape[1])]\n",
    "print('edges created')            \n",
    "\n",
    "### Create an igraph from edges\n",
    "g = ig.Graph(edges=edges)\n",
    "print('graph created')\n",
    "\n",
    "### Perform Leiden clustering on the constructed graph\n",
    "partition = la.find_partition(g, la.RBConfigurationVertexPartition, resolution_parameter=0.3)\n",
    "print('clustering done')\n",
    "\n",
    "adata.obs['leiden_spatial'] = partition.membership\n",
    "    \n",
    "   \n",
    "### Fit and transform the data using the precomputed graph\n",
    "adata.obsm['umap_graph_spatial'] = reducer.fit_transform(spatial)\n",
    "print('umap done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot embeddings for both spatial and non-spatial clustering\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.scatterplot(x=adata.obsm['umap_graph_spatial'][:,0], y=adata.obsm['umap_graph_spatial'][:,1], hue=adata.obs['leiden_spatial'], palette='tab20b', s=3, ax=axes[0])\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "sns.scatterplot(x=adata.obs['x_location'], y=adata.obs['y_location'], hue=adata.obs['leiden_spatial'], s=1, palette='tab20b', ax=axes[1])\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LET'S STOP AND REVIEW\n",
    "> 1. What did we just do? \n",
    "> 2. Which matters more, non-spatial or spatial? \n",
    "> 3. When choosing a spatial method or developing one, what are the parameters that we need to consider?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "LECTURE :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "PRACTICE ON YOUR OWN : <br>\n",
    "Below is a script adapted from xxx. <br>\n",
    "Before running each cell, think about what the alogorithm is working on to incorporate spatial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. FIRST WE WILL PERFORM A NEAREST NEIGHBOR BASED DISTANCE CALCULATION TO COMPUTE THE NECESSARY DISTANCES BETWEEN THE CELLS\n",
    "'''\n",
    "from Banksy_py.banksy.main import median_dist_to_nearest_neighbour\n",
    "\n",
    "# set params\n",
    "# ==========\n",
    "plot_graph_weights = True\n",
    "k_geom = 15 # only for fixed type\n",
    "max_m = 1 # azumithal transform up to kth order\n",
    "nbr_weight_decay = \"scaled_gaussian\" # can also be \"reciprocal\", \"uniform\" or \"ranked\"\n",
    "\n",
    "# Find median distance to closest neighbours, the median distance will be `sigma`\n",
    "nbrs = median_dist_to_nearest_neighbour(adata, key = 'spatial')\n",
    "\n",
    "from banksy.initialize_banksy import initialize_banksy\n",
    "\n",
    "banksy_dict = initialize_banksy(\n",
    "    adata,\n",
    "    ('x_location', 'y_location', 'spatial'),\n",
    "    k_geom,\n",
    "    nbr_weight_decay=nbr_weight_decay,\n",
    "    max_m=max_m,\n",
    "    plt_edge_hist=False,\n",
    "    plt_nbr_weights=False,\n",
    "    plt_agf_angles=False, # takes long time to plot\n",
    "    plt_theta=False,\n",
    ")\n",
    "\n",
    "banksy_dict\n",
    "\n",
    "### remove all the warnings and messages from the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. NEXT WE WILL CONSTRUCT A BANKSY MATRIX\n",
    "'''\n",
    "\n",
    "from Banksy_py.banksy.embed_banksy import generate_banksy_matrix\n",
    "\n",
    "### the following are the main hyperparamters for the banksy algorithm\n",
    "### ------------------------------------------------------------------\n",
    "\n",
    "resolutions = [0.3] ### clustering resolution for umap\n",
    "pca_dims = [18] ### Dimensionality to which to reduce data to\n",
    "lamda_list = [0, 0.25, 0.50, 0.75, 1.00] ### list of lamda values, setting higher value will result in more domain specific clustering\n",
    "\n",
    "banksy_dict, banksy_matrix = generate_banksy_matrix(adata, banksy_dict, lamda_list, max_m, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### append non-spatial results to the banksy_dict for comparison\n",
    "\n",
    "from banksy.main import concatenate_all\n",
    "banksy_dict['nonspatial'] = {### here we append the non-spatial matrix (adata.X) to obtain the non-spatial clustering results\n",
    "    0.0: {\"adata\": concatenate_all([adata.X], 0, adata=adata), }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. BANKSY APPLIES PCA AND UMAP OVER THE SPATIAL DERIVED MATRIX, FOLLOWING BY LEIDEN CLUSTERING\n",
    "'''\n",
    "\n",
    "from banksy_utils.umap_pca import pca_umap\n",
    "\n",
    "pca_umap(banksy_dict,\n",
    "         pca_dims = pca_dims,\n",
    "         add_umap = True,\n",
    "         plt_remaining_var = False,\n",
    "         verbose = False)\n",
    "\n",
    "from banksy.cluster_methods import run_Leiden_partition\n",
    "seed=329\n",
    "\n",
    "results_df, max_num_labels = run_Leiden_partition(\n",
    "    banksy_dict,\n",
    "    resolutions,\n",
    "    num_nn = 50,\n",
    "    num_iterations = -1,\n",
    "    partition_seed = seed,\n",
    "    match_labels = True,\n",
    "    verbose = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Save the results to appropriates slots back to the priginal adata object\n",
    "\n",
    "p_names = results_df.index\n",
    "\n",
    "for p_name in p_names:\n",
    "    labels = results_df.loc[p_name, 'relabeled']\n",
    "    adata_results = results_df.loc[p_name, \"adata\"]\n",
    "    adata_results\n",
    "\n",
    "    #pc_temp = adata_results.obsm(f\"reduced_pc {pca_dims[0]}\")\n",
    "    #pca_umap = adata_results.obsm(f\"umap {pca_dims[0]}\")\n",
    "\n",
    "    label_name = f\"labels_{p_name}\"\n",
    "    label_name\n",
    "\n",
    "    print(label_name)\n",
    "    adata_results.obs[label_name] = np.char.mod('%d', labels.dense)\n",
    "    adata_results.obs[label_name] = adata_results.obs[label_name].astype('category')\n",
    "    adata.obs = adata.obs.reindex(adata_results.obs.index)\n",
    "    adata.obs[label_name] = adata_results.obs[label_name]\n",
    "\n",
    "adata.obsm['pc18_banksy'] = adata_results.obsm['reduced_pc_18'].copy()\n",
    "adata.obsm['umap18_banksy'] = adata_results.obsm['reduced_pc_18_umap'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT AND DISCUSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.embedding(adata, basis='umap18_banksy', color='cell_label', show=False)\n",
    "sc.pl.embedding(adata, basis='umap18_banksy', color='labels_nonspatial_pc18_nc0.00_r0.30', show=False)\n",
    "sc.pl.embedding(adata, basis='umap18_banksy', color='labels_scaled_gaussian_pc18_nc0.25_r0.30', show=False)\n",
    "sc.pl.embedding(adata, basis='umap18_banksy', color='labels_scaled_gaussian_pc18_nc0.75_r0.30', show=False)\n",
    "sc.pl.embedding(adata, basis='umap18_banksy', color='labels_scaled_gaussian_pc18_nc1.00_r0.30', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# Create the figure with GridSpec\n",
    "fig = plt.figure(figsize=(21, 4.5))\n",
    "gs = gridspec.GridSpec(1, 5, width_ratios=[1, 0.2, 1, 1, 0.2])\n",
    "color = sns.color_palette('tab20b', 15)\n",
    "\n",
    "# First subplot for cell labels\n",
    "ax0 = plt.subplot(gs[0])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='cell_label', palette=color, s=0.9, alpha=0.5, ax=ax0)\n",
    "ax0.set_title('Cell Label', fontsize=9, loc='left')\n",
    "ax0_legend = ax0.legend_  # Capture the legend object\n",
    "ax0.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "# Empty subplot for cell label legend\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.axis('off')\n",
    "handles_cell_labels = [mlines.Line2D([], [], color=legend_handle.get_color(), marker='o', linestyle='', markersize=5)\n",
    "                       for legend_handle in ax0_legend.legendHandles]\n",
    "labels_cell_labels = [t.get_text() for t in ax0_legend.get_texts()]\n",
    "ax1.legend(handles_cell_labels, labels_cell_labels, loc='center', ncol=1, fontsize=8, title='cell_label')\n",
    "\n",
    "# Second subplot for non-spatial clustering\n",
    "ax2 = plt.subplot(gs[2])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_nonspatial_pc18_nc0.00_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax2)\n",
    "ax2.set_title('Non-spatial clustering', fontsize=9, loc='left')\n",
    "ax2_legend = ax2.legend_  # Capture the legend object\n",
    "ax2.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "# Third subplot for spatial clustering\n",
    "ax3 = plt.subplot(gs[3])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_scaled_gaussian_pc18_nc0.75_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax3)\n",
    "ax3.set_title('Spatial clustering', fontsize=9, loc='left')\n",
    "ax3.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "# Empty subplot for cluster legend\n",
    "ax4 = plt.subplot(gs[4])\n",
    "ax4.axis('off')\n",
    "handles_clusters = [mlines.Line2D([], [], color=legend_handle.get_color(), marker='o', linestyle='', markersize=5)\n",
    "                    for legend_handle in ax2_legend.legendHandles]\n",
    "labels_clusters = [t.get_text() for t in ax2_legend.get_texts()]\n",
    "ax4.legend(handles_clusters, labels_clusters, loc='center', ncol=1, fontsize=8, title='clusters')\n",
    "\n",
    "# Adjust the space between the subplots\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# Create the figure with GridSpec\n",
    "fig = plt.figure(figsize=(30, 4.5))\n",
    "gs = gridspec.GridSpec(1, 6, width_ratios=[1, 1, 1, 1, 1, 0.2])\n",
    "color = sns.color_palette('tab20')\n",
    "\n",
    "# First subplot for cell labels\n",
    "ax0 = plt.subplot(gs[0])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_nonspatial_pc18_nc0.00_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax0)\n",
    "ax0.set_title('Non-spatial clustering', fontsize=9, loc='left')\n",
    "ax0_legend = ax0.legend_  # Capture the legend object\n",
    "ax0.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "\n",
    "# Second subplot for non-spatial clustering\n",
    "ax1 = plt.subplot(gs[1])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_scaled_gaussian_pc18_nc0.25_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax1)\n",
    "ax1.set_title('Spatial clustering - 0.25', fontsize=9, loc='left')\n",
    "ax1.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "## Third subplot for spatial clustering\n",
    "ax2 = plt.subplot(gs[2])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_scaled_gaussian_pc18_nc0.50_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax2)\n",
    "ax2.set_title('Spatial clustering', fontsize=9, loc='left')\n",
    "ax2.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "\n",
    "# Third subplot for spatial clustering\n",
    "ax3 = plt.subplot(gs[3])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_scaled_gaussian_pc18_nc0.75_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax3)\n",
    "ax3.set_title('Spatial clustering - 0.75', fontsize=9, loc='left')\n",
    "ax3.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "# Third subplot for spatial clustering\n",
    "ax4 = plt.subplot(gs[4])\n",
    "sns.scatterplot(data=adata.obs, x='x_location', y='y_location', hue='labels_scaled_gaussian_pc18_nc1.00_r0.30', palette=color, s=0.9, alpha=0.5, ax=ax4)\n",
    "ax4.set_title('Spatial clustering - 1.00', fontsize=9, loc='left')\n",
    "ax4.get_legend().remove()  # Remove the legend from the plot\n",
    "\n",
    "\n",
    "# Empty subplot for cluster legend\n",
    "ax5 = plt.subplot(gs[5])\n",
    "ax5.axis('off')\n",
    "handles_clusters = [mlines.Line2D([], [], color=legend_handle.get_color(), marker='o', linestyle='', markersize=5)\n",
    "                    for legend_handle in ax0_legend.legendHandles]\n",
    "labels_clusters = [t.get_text() for t in ax0_legend.get_texts()]\n",
    "ax5.legend(handles_clusters, labels_clusters, loc='center', ncol=1, fontsize=8, title='clusters')\n",
    "\n",
    "# Adjust the space between the subplots\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Create the figure with GridSpec\n",
    "fig = plt.figure(figsize=(15, 4.5))\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.2])\n",
    "\n",
    "# First plot\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "sns.histplot(data=adata.obs, x='labels_nonspatial_pc18_nc0.00_r0.30', hue='cell_label', palette='tab20b', multiple='stack', shrink=0.8, ax=ax1)\n",
    "ax1.get_legend().remove()  # Remove the legend from the first plot\n",
    "\n",
    "# Second plot\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "sns.histplot(data=adata.obs, x='labels_scaled_gaussian_pc18_nc0.75_r0.30', hue='cell_label', palette='tab20b', multiple='stack', shrink=0.8, ax=ax2)\n",
    "ax2_legend = ax2.legend_  # Get the legend from the second plot\n",
    "ax2.get_legend().remove()  # Remove the legend from the second plot\n",
    "\n",
    "# Add the legend to the figure in the third GridSpec cell\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "handles, labels = ax2_legend.legendHandles, [t.get_text() for t in ax2_legend.get_texts()]\n",
    "fig.legend(handles, labels, loc='center right', ncol=1, fontsize=8, title='cell_label', bbox_to_anchor=(.985, 0.55))\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
